{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import psycopg2\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishing connection to db\n",
    "conn = psycopg2.connect(\"host=10.0.0.3 port=5432 dbname=pid-portal user=postgres password=passwd\") \n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.execute(\"\"\"select avg_delay from \"Trip_delay\" where trip_id='332_638_190831' and day_nr=1\"\"\") #just simple select to check if connection is working\n",
    "cur.fetchone() is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digest(file):\n",
    "    f = open(file, 'r')\n",
    "    raw_data = f.read()\n",
    "    #raw_data.replace('{\"features\":', '/n{\"features\":')\n",
    "    #raw_data.replace('/n{\"features\":', '', 1)\n",
    "    #lines = raw_data.split('\\n')\n",
    "    d = '}{'\n",
    "    lines =  ['{' + e + '}' for e in raw_data.split(d) if e]\n",
    "    \n",
    "    lines[0] = lines[0].replace('{{', '{', 1)\n",
    "    lines[-1] = lines[-1].replace('\"type\":\"Feature\"}],\"type\":\"FeatureCollection\"}}', '\"type\":\"Feature\"}],\"type\":\"FeatureCollection\"}')\n",
    "    \n",
    "    data = []\n",
    "    for line in lines:\n",
    "        if line != '':\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except:\n",
    "                exc_file = open('err_line', 'a')\n",
    "                exc_file.write(line + '\\n')\n",
    "                exc_file.close()\n",
    "        \n",
    "    \n",
    "    #df = pd.read_json(file, lines=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_unix_to_date(unix_ts):\n",
    "    try:\n",
    "        return datetime.fromtimestamp(int(unix_ts[:-3])).strftime('%Y-%m-%d %H:%M:%S')\n",
    "    except:\n",
    "        return unix_ts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_single_file(entry):\n",
    "    i = 0\n",
    "    for line in entry:\n",
    "        for data in line['features']:\n",
    "            cur.execute(\"\"\"\n",
    "                INSERT INTO public.\"Vehicle_position\"(\n",
    "                route_id, \"timestamp\", bearing, calculated_delay, speed, longitude, latitude, vehicle_id, trip_id, is_canceled, next_stop_id, delay_stop_departure, delay_stop_arrival, distance_traveled)\n",
    "                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
    "                \"\"\",\n",
    "               (data['properties']['trip']['gtfs_route_id'],convert_unix_to_date(data['properties']['last_position']['origin_timestamp']), \n",
    "                data['properties']['last_position']['bearing'], data['properties']['last_position']['delay'],\n",
    "                data['properties']['last_position']['speed'], data['properties']['last_position']['lng'], data['properties']['last_position']['lat'],\n",
    "                data['properties']['trip']['cis_vehicle_registration_number'], data['properties']['trip']['gtfs_trip_id'], data['properties']['last_position']['is_canceled'],\n",
    "                data['properties']['last_position']['gtfs_next_stop_id'], \n",
    "                data['properties']['last_position']['delay_stop_departure'],\n",
    "                data['properties']['last_position']['delay_stop_arrival'],\n",
    "                data['properties']['last_position']['gtfs_shape_dist_traveled']\n",
    "               ))\n",
    "        #trip delays\n",
    "            if data['properties']['last_position']['delay_stop_departure'] != None:\n",
    "                cur.execute(\"\"\"\n",
    "        INSERT INTO public.\"Trip_delay\"(\n",
    "\t\ttrip_id, day_nr, avg_delay, cnt)\n",
    "\t\tVALUES (%s, extract(isodow from date %s), %s, 1) ON CONFLICT (trip_id,day_nr) DO UPDATE \n",
    "\t  SET avg_delay = (%s + \"Trip_delay\".cnt * \"Trip_delay\".avg_delay)/(\"Trip_delay\".cnt+1), cnt = \"Trip_delay\".cnt+1 ;\n",
    "        \"\"\", (data['properties']['trip']['gtfs_trip_id'], convert_unix_to_date(data['properties']['last_position']['origin_timestamp'][:-3]), data['properties']['last_position']['delay_stop_departure'],\n",
    "         data['properties']['last_position']['delay_stop_departure']))\n",
    "        #section delays\n",
    "                cur.execute(\"\"\"\n",
    "        UPDATE public.\"Trip_sections\"\n",
    "\t\tSET last_delay=%s,\n",
    "\t\tavg_delay = case when avg_delay is null then %s else (%s+(\"Trip_sections\".delay_counter*\"Trip_sections\".avg_delay))/(\"Trip_sections\".delay_counter+1) end,\n",
    "\t\tdelay_counter = case when delay_counter is null then 1 else delay_counter+1 end\n",
    "\t\tWHERE trip_id=%s and destination=%s;\n",
    "        \"\"\", (data['properties']['last_position']['delay_stop_departure'], data['properties']['last_position']['delay_stop_departure'], data['properties']['last_position']['delay_stop_departure'], data['properties']['trip']['gtfs_trip_id'], data['properties']['last_position']['gtfs_next_stop_id']))\n",
    "        #filling the vehicle table from the position data\n",
    "            cur.execute(\"\"\"\n",
    "        INSERT INTO public.\"Vehicle\"(\n",
    "\tvehicle_id, vehicle_type, agency)\n",
    "\tVALUES (%s, %s, %s)\n",
    "        ON CONFLICT (vehicle_id) DO UPDATE \n",
    "        SET vehicle_type = excluded.vehicle_type, agency = excluded.agency;\n",
    "        \"\"\", (data['properties']['trip']['cis_vehicle_registration_number'], data['properties']['trip']['vehicle_type'], data['properties']['trip']['cis_agency_name'])\n",
    "                   )\n",
    "        i += 1\n",
    "    print('Executed {} entries for table Vehicle_position'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now working on file: <DirEntry '20051154001520571'>\n",
      "Executed 118 entries for table Vehicle_position\n"
     ]
    }
   ],
   "source": [
    "#entries = [digest(entry) for entry in os.scandir('/mnt/d/data_diplomka/vehicle_positions/') if entry.is_file()]\n",
    "entries = []\n",
    "i = 0\n",
    "for entry in os.scandir('/mnt/c/data_diplomka/vehicle_position_test/'):\n",
    "    if entry.is_file():\n",
    "        #data = digest(entry)\n",
    "        #break\n",
    "        print('Now working on file: {}'.format(entry))\n",
    "        insert_single_file(digest(entry))\n",
    "        conn.commit()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conn.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bool_from_int_for_wheelchair(bool_val):\n",
    "    if bool_val == 1:\n",
    "        return \"1\"\n",
    "    else:\n",
    "        return \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digest_stops(file):\n",
    "    f = open(file, 'r')\n",
    "    data = [json.loads(line) for line in open(file, 'r')]\n",
    "    #data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [digest_stops(entry) for entry in os.scandir('/mnt/c/data_diplomka/stops') if entry.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries[1][0]['properties']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for file in entries:\n",
    "    for a in file:\n",
    "    \n",
    "        cur.execute(\"\"\"\n",
    "    INSERT INTO public.\"Stop\"(\n",
    "\tstop_id, name, latitude, longitude, zone_id, wheelchair_acc)\n",
    "\tVALUES (%s, %s, %s, %s, %s, %s);\n",
    "    \"\"\",(a['properties']['stop_id'], a['properties']['stop_name'], a['properties']['stop_lat'], a['properties']['stop_lon'], a['properties']['zone_id'], \n",
    "        get_bool_from_int_for_wheelchair(a['properties']['wheelchair_boarding'])\n",
    "        ))\n",
    "        i += 1\n",
    "    print('Executed {} entries for table Stop'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digest_routes(file):\n",
    "    f = open(file, 'r')\n",
    "    data = [json.loads(line) for line in open(file, 'r')]\n",
    "    #data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [digest_routes(entry) for entry in os.scandir('/mnt/c/data_diplomka/shapes') if entry.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries[1][0]['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for route in entries:\n",
    "    for point in route[0]['features']:\n",
    "        cur.execute(\"\"\"\n",
    "        INSERT INTO public.\"Route\"(\n",
    "        route_id, \"order\", distance, latitude, longitude, stop_id)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        \"\"\", \n",
    "                    (point['properties']['shape_id'], point['properties']['shape_pt_sequence'], point['properties']['shape_dist_traveled'], point['properties']['shape_pt_lat'],\n",
    "                    point['properties']['shape_pt_lon'], '')\n",
    "                   )\n",
    "        i += 1\n",
    "        \n",
    "print('Executed {} entries for stops'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digest_trips(file):\n",
    "    f = open(file, 'r')\n",
    "    data = [json.loads(line) for line in open(file, 'r')]\n",
    "    #data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [digest_trips(entry) for entry in os.scandir('/mnt/c/data_diplomka/trips') if entry.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in entries:\n",
    "    for entry in file:\n",
    "        cur.execute(\"\"\"\n",
    "        INSERT INTO public.\"Trip\"(\n",
    "\ttrip_id, route_id, shape_id, direction, bikes_allowed, headsign)\n",
    "\tVALUES (%s, %s, %s, %s, %s, %s);\"\"\", \n",
    "                    (entry['trip_id'], entry['route_id'], entry['shape_id'], get_bool_from_int_for_wheelchair(entry['direction_id']), get_bool_from_int_for_wheelchair(entry['bikes_allowed']),\n",
    "                    entry['trip_headsign'])\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digest_st_times(file):\n",
    "    f = open(file, 'r')\n",
    "    data = [json.loads(line) for line in open(file, 'r')]\n",
    "    #data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = [digest_st_times(entry) for entry in os.scandir('/mnt/c/data_diplomka/stop_times') if entry.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in entries:\n",
    "    for entry in file:\n",
    "        cur.execute(\"\"\"\n",
    "        INSERT INTO public.stop_time(\n",
    "\ttrip_id, stop_id, sequence, arival_time, departure_time)\n",
    "\tVALUES (%s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (trip_id, stop_id, sequence) DO UPDATE \n",
    "  SET trip_id = excluded.trip_id, \n",
    "  stop_id = excluded.stop_id,\n",
    "  sequence = excluded.sequence,\n",
    "  arival_time = excluded.arival_time,\n",
    "  departure_time = excluded.departure_time\n",
    "  ;\"\"\", \n",
    "                    (entry['trip_id'], entry['stop_id'], entry['stop_sequence'], entry['arrival_time'],\n",
    "                    entry['departure_time'])\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.commit() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"\"\"\n",
    "INSERT INTO public.\"Trip_sections\" (source, destination, sequence, trip_id)\n",
    "(select st1.stop_id as source, st2.stop_id as destination, st1.sequence, st1.trip_id\n",
    "from \"stop_time\" as st1, \"stop_time\" as st2 \n",
    "where st1.trip_id=st2.trip_id and st2.sequence = st1.sequence+1 \n",
    " \n",
    ") on conflict DO NOTHING;\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
